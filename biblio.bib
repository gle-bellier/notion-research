@article{chen2020wavegrad,
  abstract = {This paper introduces WaveGrad, a conditional model for waveform generation which estimates gradients of the data density. The model is built on prior work on score matching and diffusion probabilistic models. It starts from a Gaussian white noise signal and iteratively refines the signal via a gradient-based sampler conditioned on the mel-spectrogram. WaveGrad offers a natural way to trade inference speed for sample quality by adjusting the number of refinement steps, and bridges the gap between non-autoregressive and},
  author   = {Chen, Nanxin and Zhang, Yu and Zen, Heiga and Weiss, Ron J and Norouzi, Mohammad and Chan, William},
  journal  = {arXiv preprint arXiv:2009.00713},
  pub_year = {2020},
  title    = {WaveGrad: Estimating gradients for waveform generation},
  venue    = {arXiv preprint arXiv â€¦}
}


@article{ho2020denoising,
 abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed},
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 journal = {arXiv preprint arXiv:2006.11239},
 pub_year = {2020},
 title = {Denoising diffusion probabilistic models},
 venue = {arXiv preprint arXiv:2006.11239}
}


